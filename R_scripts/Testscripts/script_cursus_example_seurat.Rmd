---
title: "single cell RNASeq analysis"
output: html_document
---

## 1. Set working directory
This is the folder on your computer that R uses to search and write files. You have to adjust this path to the folder on your computer that contains the unzipped data folder.
```{r setup}
#setwd("~/training/zelfgegeven/single-cell/Dalia/BasicScript/")

knitr::opts_knit$set(root.dir = rprojroot::find_rstudio_root_file()) 
```

You have to adjust the path so that it points to the correct folder on your computer. 

## 2. Load packages
Load the packages that you are going to use for the analysis in the memory of your computer.
```{r message=FALSE, warning=FALSE}
library(Seurat)
library(scater)
library(ggvenn)
library(ggpubr)
library(dplyr)
```

## 3. Load data
Data can be loaded in 2 ways: 

-   Using the (filtered) gene expression matrix  
-   Using the h5 file generated by Cellranger count/aggregate  

These H5 files are a special data format that allow to analyze the data on disk instead of in the memory of your computer.  

The structure and the names of the output folders and files that are generated by Cellranger 2 and by Cellranger v3 differs because v3 supports the processing of feature barcodes.

### Output generated by Cellranger v2
-   **single sample**: filtered_gene_bc_matrices/SPECIES
-   **aggregated samples**: filtered_gene_bc_matrices_mex/SPECIES
-   **H5** file: filtered_gene_bc_matrices_h5.h5

### Output generated by Cellranger v3
-   **single and aggregated samples**: filtered_feature_bc_matrix/
-   **H5** file: filtered_feature_bc_matrix.h5

### Read expression matrices generated by Cellranger
Read10X() arguments:

- folder with output of Cellranger

The function returns a sparse matrix with the RNASeq data or in case there are multiple data types (e.g. CiteSeq data) a list containing a sparse matrix of the data from each type.

#### Cellranger v2
We are not going to use this code.
```{r}
#rawData <- Read10X("Citeseq_mouse_GBM/filtered_gene_bc_matrices_mex/mm10")
#rawData <- as.matrix(rawData)
```

#### Cellranger v3
For the training we use data generated by v3. 
```{r}
data <- Read10X("Data/filtered_feature_bc_matrix_MouseGBMciteSeq/Citeseq_mouse_GBM/filtered_feature_bc_matrix")
names(data) <- c("GE","AB")
data.RNA <- as.matrix(data$GE)
data.AB <- as.matrix(data$AB)
rm(data)
```

These are CITESeq data so 2 count matrices are generated:  

- one with the gene expression values
- one with the cell surface protein abundances

```{r}
saveRDS(data.RNA,file="RNAasmatrix.rds")
```

#### Read h5-file generated by Cellranger v2
We are not going to use this code.
```{r}
#rawData <- Read10X_h5("Citeseq_mouse_GBM/filtered_gene_bc_matrices_h5.h5")
```

#### Read h5-file generated by Cellranger v3
We are not going to use this code.
```{r}
#rawData <- Read10X_h5("Citeseq_mouse_GBM/filtered_feature_bc_matrix.h5")
```

### Clean data
Look at the first 5 colums and rows of the data set:

- Cells are labeled with a barcode
- Raw counts (integer) are preferred over TPMs (float)  

If the data set contains TPMs (floating point number) that's OK since Seurat can handle TPMs. However, if the data set contains logs (smaller floating point number than TPMs), that's not OK. In the latter case you will have to skip the normalization step and use the original counts as normalized counts. 
```{r}
data.RNA[1:5,1:5]
```

**What percentage of counts is equal to 0?**  
The percentage of zero counts is equal to the total number of zeros divided by the total number of counts
```{r}
total.zeros <- sum(data.RNA==0) 
total.counts <- nrow(data.RNA) * ncol(data.RNA)
(total.zeros/total.counts) * 100
```

Almost all counts are equal to 0! This is a well-known issue in sc data. In bulk RNASeq 10-40% of the counts are 0, in sc data that proportion can be 90%.  

**Where do these zeros come from?**
There are two sources of zeros in scRNASeq data:  

- biological: genes that are not transcribed at all or genes that are transcribed but their transcripts are degraded at a faster rate than the transcription rate. Obviously these zeros are meaningful. 
- non-biological: inefficient reverse transcription, PCR or sequencing. These zeros are not real zeros: they represent genes that are transcribed but are hard to amplify (e.g. because they are GC-rich or form secondary structures) or genes with low expression levels (below detection level).   

Unfortunately there's no way to make a distinction between biological and non-biological zeroes unless you use spike-in transcripts with known concentrations.  

**How many genes are expressed in each cell?**  

- A gene is considered expressed when count > 0
- Cells are the columns in the count matrix hence MARGIN=2  
- sum(x > 0) calculates number of genes with non-zero counts
```{r}
cellCounts <- apply(data.RNA,2,function(x) sum(x > 0)) 
```

cellCounts is a vector with the number of expressed genes for every cell.
```{r}
cellCounts[1:5]
```

We will clean the huge matrix to make it easier to process:  

1. Cells with less than 200 expressed genes are removed.
```{r}
dim(data.RNA)
data.RNA <- data.RNA[,cellCounts>=200]
data.AB <- data.AB[,cellCounts>=200]
dim(data.RNA)
dim(data.AB)
```

Also remove these cells in the Ab data to generate matching matrices.  

**For each gene: in how many cells is it expressed?**  

- A gene is considered expressed if count > 0  
- Genes are the rows in the count matrix hence MARGIN=1  
- sum(x > 0) calculates number of cells with non-zero counts
```{r}
geneCounts <- apply(data.RNA,1,function(x) sum(x > 0))
```

geneCounts is a vector with the number of expressed cells for each gene
```{r}
geneCounts[1:5]
```
  
2. Genes that are expressed in less than 3 cells are removed.
```{r}
data.RNA <- data.RNA[geneCounts>=3,]
dim(data.RNA)
```

?? Why not do the same with data.AB?

### Questions
- What is the name of the first gene in the count matrix? Mrpl15
- What is the barcode of the first cell in the count matrix? AAACCCACAAGCGCTC-1
- What is the count of the first gene in the first cell? 0
- How many counts in the count matrix? 205628383
- How many counts are equal to 0? 434223444
- Is gene Xcr1 expressed in second cell? no
- Which database to search for data set GSE166635? GEO (gene expression omnibus)
- How many samples in this data set? 2
- Where to download the count matrix of the first sample? click on it
- Download the first sample of data set GSE114988
- Import this file into R 
- Convert it to a matrix that is ready for use
- What's the percentage of zeros in this data set?

Remove obsolete variables
```{r}
rm(total.counts)
rm(total.zeros)
rm(cellCounts)
rm(geneCounts)
saveRDS(data.RNA,file="RNAclean.rds")
```

## 4. Convert to SingleCellExperiment object
Scater needs the data in a Single Cell Experiment object, where the counts are stored in the assays slot.  
```{r}
sce <- SingleCellExperiment(assays=list(counts=data.RNA)) 
rm(data.RNA)
```

Convert -1 and -2 in the names of the cells to actual sample labels: WT and KO
```{r}
label <- substr(colnames(sce),18,18) 
names <- c("KO","WT")
colData(sce)$sample <- names[as.numeric(label)]
```

Now you know for every cell the sample that it comes from. 

## 5. Quality control of cells user scater
### Identify mitochondrial transcripts
Gene names are used as row names in the count matrix. To find the mitochondrial genes we need to look for row names that start with mt-  

grepl() checks if words contain a pattern and returns booleans:

- *^* in the pattern argument means starts with. Check out [this tutorial on regular expressions in R](https://r4ds.had.co.nz/strings.html#matching-patterns-with-regular-expressions).
- *ignore.case=TRUE*: in mouse names of mitochondrial genes start with **mt**, in human with **MT**  
```{r}
is.mito <- grepl("^mt-",rownames(sce),ignore.case=TRUE) 
```

The function returns a vector with Booleans:  

- **TRUE** if the name of a row (=gene) starts with mt or MT
- **FALSE** if the name of a row (=gene) does not start with mt or MT  

For plants, chloroplast genes are used instead of mitochondrial genes. Ask Thomas for more details.  

Mitochondrial genes can be used to identify unhealthy cells. When cells are exposed to stress, their cell membrane becomes leaky. When this happens:

- transcripts go though the tears in the membrane
- large mitochondria stay inside the cell
- mitochondria are the last organelles to degrade  

Enrichment of mitochondrial transcripts is therefore a clear indication of cell stress.

### Calculate QC metrics per cell
Use addPerCellQC() from scater.  

Arguments of this function:

- *input*: count matrix
- *subsets*: a named list (objects in the list have labels) with booleans or names of genes that can be used as controls like mitochondrial genes  
```{r}
sce <- addPerCellQC(sce,subsets=list(Mt=is.mito))
```

The quality metrics are stored in the colData slot of sce: 
```{r}
head(colData(sce),2) 
```

Six quality metrics are calculated for every cell (=row):

- **detected**: number of expressed genes (count > 0) (**nGene**)
- **sum**: number of transcripts (total count or library size) (**nUMI**)
- **subsets_Mt_percent**: percentage counts of mitochondrial genes  (**mito**)

We are going to rename these columns:
```{r}
names(colData(sce))[c(2,3,6)] <- c("nUMI","nGene","mito")
```  

Make sure you change the names of the right columns!  

### Questions
- What if the samples are not specified by _1 and _2 but by _C and _T? How to add a column called treatment to the coldata that contains the following names: control for _C and treated for _T? What changes in the following code:  

```{r}
colnames(sce) <- gsub("_C", "_1", colnames(sce))
colnames(sce) <- gsub("_T", "_2", colnames(sce))
label <- substr(colnames(sce),18,18)  
names <- c("control","treated")  
colData(sce)$treatment <- names[as.numeric(label)] 
```

```{r}
label <- substr(colnames(sce),18,18)  
colData(sce)$treatment <- ifelse(label == "C", "control", "treated")
```

- What if there are 3 samples: _C, _T1 and _T2? You want a column called treatment in the coldata with the following names: control, treat1, treat2. 
```{r}
colnames(sce) <- gsub("_C", "_1", colnames(sce))
colnames(sce) <- gsub("_T1", "_2", colnames(sce))
colnames(sce) <- gsub("_T2", "_3", colnames(sce))
label <- substr(colnames(sce),18,18)  
names <- c("control","treat1", "treat2")  
colData(sce)$treatment <- names[as.numeric(label)]
```

- How many mitochondrial genes in the data set?
```{r}
sum(is.mito)
#13
```

- How many ribosomal genes are in the data set?
*Tip*: their name starts with RPS or RPL
```{r}
is.ribo <- grepl("^RP[SL]",rownames(sce),ignore.case=TRUE) 
sum(is.ribo)
#111
```

- You often don't want to sequence ribosomal RNAs, you're interested in mRNA. This is why rRNA depletion is included in the library prep. High percentages of ribosomal transcripts indicate that few of the lowly expressed genes will be detected. How to calculate pct ribosomal transcripts as a quality measure? 
```{r}
sce2 <- addPerCellQC(sce,subsets=list(Mt=is.mito,
                                     Rb = is.ribo))
colData(sce2)[1:2,]

```

- Sometimes variations on gene symbols are being used like GRH38___brca2. How to adjust the regular expression in this case? 
```{r}
is.mito <- grepl("^GRH38___mt-",rownames(sce),ignore.case=TRUE) 
```

- What changes to this line of code when you work on 1 sample instead of an aggregate of 2 samples?    

```{r}
names(colData(sce))[c(2,3,6)] <- c("nUMI","nGene","mito")
#you don't have a sample column
names(colData(sce))[c(1,2,5)] <- c("nUMI","nGene","mito")

```

- What does the addPerCellQC() command look like when you don't have any control genes?

## 6. Detect outliers cells using scater
Outlier cells are: 

1. cells with low number of genes (or UMIs) expressed 
2. cells with high percentage of mitochondrial transcripts

isOutlier() identifies outlier cells for each of these metrics:

1. cells with extreme log-library size
2. cells with extreme percentage of mitochondrial genes

Extreme is defined by a certain number of MADs from the median.  

This is a trial and error process: 

- you choose a number of MADs
- create plots
- inspect the plots
- change the threshold for number of MADs
- repeat until it looks ok

Use isOutlier() from scater.  

Arguments of this function:

- *input*: values for the metric you want to use
- *nmads*: threshold for number of MADs. The lower you set this, the more outliers will be found. 
- *type*: find outliers at both tails (default) or only at lower end (= too few) or only at higher end (= too many)
- *log*: do you want to take log10 of metric values before computing MAD?

### UMI counts per cell
We identify cells with very high and cells with very low library sizes separately and we log transform the library sizes before calculating the median and the distances to the median.  
```{r}
colData(sce)$nUMI.out.low <- isOutlier(colData(sce)$nUMI,nmads=3,type="lower",log=TRUE) 
colData(sce)$nUMI.out.high <- isOutlier(colData(sce)$nUMI,nmads=3,type="higher",log=TRUE)
sum(colData(sce)$nUMI.out.low | colData(sce)$nUMI.out.high)
```

### Number of expressed genes per cell
```{r}
colData(sce)$nGene.out.low <- isOutlier(colData(sce)$nGene,nmads=3,type="lower",log=TRUE) 
colData(sce)$nGene.out.high <- isOutlier(colData(sce)$nGene,nmads=3,type="higher",log=TRUE) 
sum(colData(sce)$nGene.out.low | colData(sce)$nGene.out.high)
```

**What causes extreme library sizes or number of expressed genes?**

- empty droplets 
- inefficient capture 
- doublets 
- cell damage

?? Why are there no cells with too small libraries?  

### Mitochondrial count percentages
?? Why only high percentages?  

Percentages should not be log transformed. 
```{r}
colData(sce)$mito.out.high <- isOutlier(colData(sce)$mito,nmads=3,type="higher") 
sum(colData(sce)$mito.out.high)
```

### Create histograms
Ggplot2 needs a data frame as input.
```{r}
metaData <- as.data.frame(colData(sce))
ggplot(metaData,aes(nUMI)) + 
  geom_histogram(binwidth=100) + 
  xlab("Count depth (total UMI count)") +
  ylab("Frequency") +
  ggtitle("Histogram of total UMI count per cell") + 
  theme_bw()
```

We know from the previous step there are no outliers with respect to library size.  

Calculate the cutoff value for outliers with respect to the number of expressed genes
```{r}
cut.nGene <- 2^(median(log2(metaData$nGene))-3*mad(log2(metaData$nGene),na.rm=TRUE))
ggplot(metaData,aes(nGene)) + 
  geom_histogram(binwidth=20) +
  xlab("Number of Genes") +
  ylab("Frequency") +
  ggtitle("Histogram of number of genes per cell") + 
  geom_vline(xintercept=cut.nGene,color="red") +
  theme_bw()
```

There are no outlier cells with exceptionally high number of expressed genes but if you want you could calculate the upper threshold in the same way and add it to the histogram.  

Calculate the cutoff value for outliers with respect to expression of  mitochondrial genes
```{r}
cut.mito <- median(metaData$mito) + 3*mad(metaData$mito,na.rm=TRUE)
ggplot(metaData,aes(mito)) + 
  geom_histogram(binwidth=0.1) +
  xlab("% Mitochondrial counts") +
  ylab("Frequency") +
  ggtitle("Histogram of % mitogenes per cell") +
  geom_vline(xintercept=cut.mito,color="red") +
  theme_bw()
```

### Create violin plots 
#### Before filtering
```{r}
ggplot(metaData,aes("",nUMI)) +
  geom_jitter(height=0,width=0.3,aes(color=nUMI.out.low)) +
   geom_violin(fill="gray80",alpha=0.5) +
  scale_color_manual(values=c("#00BFC4","#F8766D")) + 
  ggtitle("Total UMI counts per cell") +
  theme_classic()
```

```{r}
ggplot(metaData,aes("",nGene)) +
  geom_jitter(height=0,width=0.3,aes(color=nGene.out.low)) +
  geom_violin(fill="gray80",alpha=0.5) +
  scale_color_manual(values=c("#00BFC4","#F8766D")) + 
  ggtitle("Number of genes per cell") +
  theme_classic()
```

```{r}
ggplot(metaData,aes("",mito)) +
  geom_jitter(height=0,width=0.3,aes(color=mito.out.high)) +
  geom_violin(fill="gray80",alpha=0.5) +
  scale_color_manual(values=c("#00BFC4","#F8766D")) + 
  ggtitle("% mitogenes per cell") +
  theme_classic()
```

#### After filtering
You can check the effect of removing outliers by recreating the plots after removal of the outliers.  

Select the cells that are not defined as outliers: non-out is  

- TRUE if any of the thresholds generates a TRUE for that cell
- FALSE if none of the thresholds generates a TRUE
```{r}
non.out <- !(metaData$nUMI.out.low | metaData$nUMI.out.high | metaData$nGene.out.low | metaData$nGene.out.high | metaData$mito.out.high)
metaData.filtered <- metaData[non.out,]
dim(metaData.filtered)
```

Now recreate the plots. 
```{r}
ggplot(metaData.filtered,aes("",nUMI)) +
  geom_jitter(height=0,width=0.3,aes(color=nUMI.out.low)) +
  geom_violin(fill="gray80",alpha=0.5) +
  scale_color_manual(values=c("#00BFC4","#F8766D")) + 
  ggtitle("Total UMI counts per cell after filtering") +
  theme_classic()
```

```{r}
ggplot(metaData.filtered,aes("",nGene)) +
  geom_jitter(height=0,width=0.3,aes(color=nGene.out.low)) +
  geom_violin(fill="gray80",alpha=0.5) +
  scale_color_manual(values=c("#00BFC4","#F8766D")) + 
  ggtitle("Number of genes per cell after filtering") +
  theme_classic()
```

```{r}
ggplot(metaData.filtered,aes("",mito)) +
  geom_jitter(height=0,width=0.3,aes(color=mito.out.high)) +
  geom_violin(fill="gray80",alpha=0.5) +
  scale_color_manual(values=c("#00BFC4","#F8766D")) + 
  ggtitle("% mito genes per cell after filtering") +
  theme_classic()
```
Here you clearly see that the plot greatly improved by removing the outliers. 

### Create Venn diagram 
So we have detected outliers cells with:  

- few expressed genes
- a lot of mitochondrial transcripts  

We are going to check if these two groups of cells overlap by making a Venn diagram. 
```{r}
ggvenn(list(nGene=rownames(metaData[metaData$nGene.out.low,]),
            mito=rownames(metaData[metaData$mito.out.high,])),
       fill_color=c("green","orange"),show_percentage=FALSE) 
```  

The two groups completely overlap so if you remove the cells with a lot of mitochondrial transcripts you automatically also remove the cells with few expressed genes. 

### Remove outliers
Cells with quality values < threshold on number of MADs thresholds are considered outliers. They are removed under the assumption that they correspond to low-quality cells.  

To this end we will keep all cells that are not marked as outlier.
```{r}
keep <- !(metaData$mito.out.high) 
sce <- sce[,keep] 
dim(sce)
```

### Questions
- What is the highest library size in the filtered data set?
- What is the lowest number of expressed genes in the filtered data set?

```{r}
rm(metaData.filtered)
rm(metaData)
rm(keep)
rm(non.out)
saveRDS(sce,file="sceUni.rds")
```

## 7. Multivariate outlier detection by PCA
We will identify outliers using a principal component analysis (PCA) since it allows to include multiple QC metrics. Hence it performs multivariate outlier detection.  

First we define which metrics we want to take into account. 

```{r}
varsToUse <- c("nUMI","nGene","mito")
```

PCA will identify cells with substantially different QC metrics as outliers. These outliers are marked and can be deleted from the dataset.  

PCA is done using runColDataPCA() from the scater package:  

- *object* input is a SCE object
- *variables* which quality metrics to use for the PCA?
- *outliers* by default it will not identify outlier cells based on the PCA, if you do want to identify outliers set to TRUE
```{r}
sce <- runColDataPCA(sce,variables=varsToUse,
                     outliers=TRUE)
```

This adds a column called **outlier** to the colData, which is accessible as colData(sce)$outlier. It contains Booleans:  

- **TRUE** for outlier cells  
- **FALSE** for ok cells 

Number of detected outliers:
```{r}
sum(colData(sce)$outlier)
```

### Draw PCA plot and color outliers
Results of the PCA can be retrieved via:
```{r}
reducedDims(sce)
```

The plot can be created using plotReducedDim() of the scater package. Arguments are:  

- *object* input is a sce object
- *dimred* more specifically the results of the PCA calculations which are stored in the PCA_coldata object of the list generated by reducedDims(sce)  
- *colour_by* the name of the column in coldata that contains the values you want to use to color the points, in this case: is the cell (point) an outlier or not?

```{r}
plotReducedDim(sce,dimred="PCA_coldata",colour_by="outlier")
```

### Violin plot 
#### Before filtering
```{r}
metaData <- as.data.frame(colData(sce))
ggplot(metaData,aes("",nUMI)) +
  geom_jitter(height=0,width=0.3,aes(color=outlier)) +
   geom_violin(fill="gray80",alpha=0.5) +
  scale_color_manual(values=c("#00BFC4","#F8766D")) + 
  ggtitle("Total UMI counts per cell") +
  theme_classic()
```

```{r}
ggplot(metaData,aes("",nGene)) +
  geom_jitter(height=0,width=0.3,aes(color=outlier)) +
   geom_violin(fill="gray80",alpha=0.5) +
  scale_color_manual(values=c("#00BFC4","#F8766D")) + 
  ggtitle("Number of genes per cell") +
  theme_classic()
```

#### After filtering
Keep the cells that are not outliers. 
```{r}
non.out <- !(metaData$outlier)
metaData.filtered <- metaData[non.out,]
dim(metaData.filtered)
```

```{r}
ggplot(metaData.filtered,aes("",nUMI)) +
  geom_jitter(height=0,width=0.3,aes(color=outlier)) +
   geom_violin(fill="gray80",alpha=0.5) +
  scale_color_manual(values=c("#00BFC4","#F8766D")) + 
  ggtitle("Total UMI counts per cell") +
  theme_classic()
```

```{r}
ggplot(metaData.filtered,aes("",nGene)) +
  geom_jitter(height=0,width=0.3,aes(color=outlier)) +
   geom_violin(fill="gray80",alpha=0.5) +
  scale_color_manual(values=c("#00BFC4","#F8766D")) + 
  ggtitle("Number of genes per cell") +
  theme_classic()
```

### Remove outliers
```{r}
keep <- !(metaData$outlier) 
sce <- sce[,keep] 
dim(sce)
```

It's needless to say that detection of outliers is a cyclic process, involving a lot of trial and error, in which input of the biologist is essential.  

## 8. Save sce object to file
Quality control is finished so save the results in an R object.  
```{r}
saveRDS(sce,file="sce.rds")
rm(list=ls())
```

## 9. Create Seurat object

**Why Seurat?**  

Because everyone uses it, it provides extensive support and documentation and it's simply a good tool.  

In a [comparison between Monocle3, the second most popular scRNA-seq toolkit, and Seurat](https://pubmed.ncbi.nlm.nih.gov/35063006/) on benchmark data from three different platforms (10x Genomics, Drop-seq and Smart-seq2), Seurat clustering was more accurate and Seurat DE analysis using MAST was found to be more robust to non-biological zeros.  

Seurat does not use a matrix nor a Single Cell Experiment. It needs a Seurat object as input.  

A Seurat object is a data type with slots to store the raw single cell RNASeq data and the analysis results. It simplifies the analysis because you do not need to keep track of many individual variables. They are all collapsed into one single Seurat object.  

Seurat objects contain: 

- 1 set of cells 
- 1 or more assays objects (=individual sets of count data)  

They can be reduced from high dimension to lower-dimension state. The results of such a dimensionality reduction are stored in the Seurat object as DimReduc objects.  

Seurat objects also store meta data.  

The various slots are accessible via @sign.  
Use CreateSeuratObject() from Seurat.

Arguments of this function:

- *counts*: input data
- *min.cells*: remove genes expressed in less than this many cells
- *min.features*: remove cells with less than this many genes expressed  
We are not going to use the two latter arguments because we already filtered low quality cells and genes with scater.

```{r}
sce <- readRDS("sce.rds")
counts <- counts(sce)
metaData <- colData(sce) 
rm(sce)
seuratObj <- CreateSeuratObject(counts=counts)
```

Make sure the gene names (rownames in the sce) are copied to and used as rownames in the counts matrix. If they are not present CreateSeuratObject() will throw an error complaining about the fact that the rownames are empty.  

Now add the meta data (cell annotation) to the Seurat object.  

```{r}
seuratObj <- AddMetaData(seuratObj,as.data.frame(metaData)) 
rm(counts)
```

Here the same remark: the cell names in the metaData data frame must match those in the Seurat object and must be used as row names in metaData (having them in a column is not good enough, they need to be row names).  

### Explore Seurat object
More details can be found on the slides.  

Seurat objects contain one or more assays objects that represent the expression data.
```{r}
seuratObj@assays
```

The counts are in the RNA object:  
Seurat object < assays slot < RNA object < counts slot

## 10. Normalization
By default Seurat uses global-scaling normalization (Log-Normalize)

1. Divide each count by the total number of counts in that cell  
This changes all counts into a relative measure.  
Mainly technical factors cause variations in the number of reads per cell, although biological factors also play a smaller role.

2. Multiply this relative measure by the scale factor (10,000 by default)

3. Log-transforms the result to stabilize the variance  

Use NormalizeData() from Seurat.  

Arguments of this function: 

- *normalization.method*: default is
log-normalization: scale all cells to 10000 reads and do a log transformation. CLR transformation is only used on CITE-Seq protein data (ADT) and cell hashes (HTO). It is not suited for data with a lot of zeroes and as such it cannot be used to normalize the UMI counts. If you want to use an alternative normalization method on UMI counts, use SCTransform(). It is explained in the e-learning system.
- *scale.factor*: default scales all cells to 10000 reads
```{r}
seuratObj <- NormalizeData(object=seuratObj)
```
**Where are these log normalized values?**  

Raw counts are in the counts slot of the RNA object
```{r}
seuratObj@assays$RNA@counts[1:5,1:10]
```

Normalized counts are in the data slot
```{r}
seuratObj@assays$RNA@data[1:5,1:10]
```

**Histogram of raw library sizes**
```{r}
ggplot(seuratObj@meta.data,aes(nUMI)) + geom_nhistogram(bins=60)
```

**Histogram of normalized library sizes**  

To this end retrieve the normalized counts from the data slot. They are stored in a matrix. For plotting you need to transform the matrix in a data frame. 
```{r}
counts.norm <- as.matrix(seuratObj@assays$RNA@data)
nUMILN <- data.frame(nUMI=colSums(counts.norm))
ggplot(nUMILN,aes(nUMI)) + geom_histogram(bins=60)
```  
  
You see that normalization reduces the variability in library sizes. 

## 11. Find highly variable genes
HVGs are genes with high variability (high meaning above background level). There are 2 reasons for focussing on the HVGs in the remainder of the pipeline:

- reduction of the data set: PCA on 2000 genes instead of 18000 is faster and easier. 
- removing technical noise: when genes vary a lot you can assume that this variation is biological. Small variation is often a representation of technical noise. In the next step we are going to scale the genes (mean=0 and variance=1). This will increase the variability of genes with low variability. So this would make the technical noise comparable to the biological variability which is of course not what you want. 

Spike-in transcripts can be used to estimate the background level but Seurat can calculate HVGs based on the data when spike-ins are not available.  

Use FindVariableFeatures() from Seurat. 

Arguments for this function:

- *object* input is Seurat object
- *selection.method*: default vst stabilizes the variance and is recommended for RNSeq data by Sajita lab. [This publication](https://jtggjournal.com/article/view/3809) compared the three methods and found that the clusters agree but that some cell assignments to clusters vary. 
- *nfeatures*: default identifies the 2000 most variable genes. This is a typical settings for UMI data that is normalized to a total of 10000 counts
- *verbose*: default print info about progress of calculations in the console  

You can retrieve the HVGs using VariableFeatures(). It returns a vector with the names of the HVGs, ordered according to decreasing standardized variance. 
```{r}
seuratObj <- FindVariableFeatures(seuratObj)
length(VariableFeatures(seuratObj)) 
head(VariableFeatures(seuratObj)) 
```
**Get info on these HVGs** (mean,variance,standardized variance)  

Available via HVFInfo(). It returns a table with mean,variance and standardized variance. 
```{r}
head(HVFInfo(seuratObj))
```  

HVGs are selected based on the last column: genes with the highest value in this column are selected as HVGs.  

**Plot variable genes**  

To create the plot that was shown in the slides use VariableFeaturePlot()
```{r}
VariableFeaturePlot(seuratObj)
```  

The red points are the HVGs.  

### Questions
- Select the 20 most variable genes. 
Hint: use VariableFeatures(seuratObj)
```{r}
top20 <- VariableFeatures(seuratObj)[1:20]
```

- Add the names of these 20 genes to the plot. 
Hint: use LabelPoints() and the output of the previous question as value for points.
```{r}
p <- VariableFeaturePlot(seuratObj)
LabelPoints(plot = p,
            points = top20,
            labels = top20,
            repel = TRUE)
```

- Selecting the 2000 most variable genes is a bit arbitrary. You could be more specific by seeing if the variance has an elbow if you plot it:  

1. Order the genes in HVFInfo() by decreasing standardized variance
2. Select the first 3000 genes
3. Create a scatter plot with 1:3000 on X and standardized variance on Y
4. Make a copy of the Seurat object
5. On that copy repeat finding HVGs but returning a lower number of HVGs
6. Make a variable feature plot for these new HVGs
7. Remove the copy  

```{r}
all_genes <- HVFInfo(seuratObj)
all_genes <- all_genes[order(all_genes$variance.standardized, decreasing = TRUE),]
top3000 <- all_genes[1:3000,]
top3000_genes <- rownames(top3000)
ggplot(top3000, aes(x = 1:3000, y = variance.standardized)) + #elbow plot: y-axis = gain: how much do I gain with the next gene added
  geom_point()

sO2 <- seuratObj
sO2 <- FindVariableFeatures(sO2,
                            nfeatures = 1000)
p2 <- VariableFeaturePlot(sO2)
top20 <- VariableFeatures(sO2)[1:20]
LabelPoints(plot = p2,
            points = top20,
            labels = top20,
            repel = TRUE)

rm(sO2)
```


## 12. Scaling
Standard pre-processing step prior to PCA  
Scaling will shift expression of each gene so that:

- mean expression across cells is 0 
- variance across cells is 1 
This will avoid that highly-expressed genes dominate the PCA  

Arguments for this function:

- *object*: Seurat object 
- *features*: which genes need to be scaled? Default: the HVGs. 

```{r}
seuratObj <- ScaleData(seuratObj)
```

Scaled values are in the scale.data slot of the RNA object
```{r}
seuratObj@assays$RNA@scale.data[1:5,1:4]
```

### Questions
- What is the raw count of this Gzma in cell 1?
```{r}
seuratObj@assays$RNA@counts["Gzma",1]
```

- What is the normalized count of this gene in cell 1?
```{r}
seuratObj@assays$RNA@data["Gzma",1]
```

- What is the standardized variance of gene Gzma?
```{r}
HVFInfo(seuratObj)["Gzma",]
#or seuratObj@assays$RNA@meta.features["Gzma",]
```

- What is the scaled count of gene Gzma in cell 1?
```{r}
seuratObj@assays$RNA@scale.data["Gzma",1]
```

- How to regress out percentage of mitochondrial transcripts and library size? Don't actually do it! If you run ScaleData again it overwrites the results from the previous run. 
```{r}
#don't do it
colnames(seuratObj@meta.data)
scaleData(seuratObj,
          vars.to.regress = c("mito", "nUMI"))
#if you set features to rownames(seuratObj) in scaleData function, you do it for all the genes - if you don't set features argument, you only do the scaling for the highly variable genes
```


## 13. PCA 
Use RunPCA() from Seurat

Arguments of the function:  

- input: scaled counts of HVGs 
- *features*: which genes to use for PCA (default: the 2000 HVGs). If you want to cluster based on a set of known genes, you can specify their names as the value for this argument. 
- *npcs*: number of PCs to calculate 
- *ndims.print*: number of PCs with highest variability to show genes with heighest weights for, here: PC1, PC2, PC3, PC4, PC5 
- *nfeatures.print*: number of genes with heighest weights to print for these 5 PCs
- *reduction.name*: default name for the PCA results is **pca**
- *reduction.key*: default name for each PC starts with **PC_** so PC_1, PC_2, PC_3... 
- *seed.use*: PCA is a process that has some randomness built-in. This parameter allows to reduce this random behavior. 

```{r}
seuratObj <- RunPCA(seuratObj,nfeatures.print=10)
```
Results are stored in the pca object of the reductions slot.  

Cell embeddings are the values obtained by projecting each cell on a PC. They define the coordinates of the cell in the PCA plot.  

Feature loadings are the contributions of each gene to the PC. High (or very negative) loadings define marker genes.  

Plots of the PCs can be made using DimPlot()  
Arguments of this function:

- *object* Seurat object, input are the dimensionality reduction results
- *reduction* use results of which dimensionality reduction: UMAP, tSNE or PCA?
- *group.by* how to color the cells (the dots on the plot)?
- *split.by* create multiple plots e.g. one for KO and one for WT. The value is the name of the column in the meta data that defines the groups.
- *dims* which PCs to plot? default is PC_1 versus PC_2
- *label*: default do not put cluster labels on the plot
- *label.size*: font size of cluster labels
- *pt.size*: size of the points
```{r}
seuratObj@reductions$pca@cell.embeddings[1:5,1:5]
seuratObj@reductions$pca@feature.loadings[1:5,1:5]
DimPlot(seuratObj,reduction="pca",group.by="sample")
```

If you see separate clusters for the different conditions you need to integrate the cells across conditions (see extras on the e-learning system)

## 14. Heat maps of the PCs
Create a heatmap for PCs 1-36: one heatmap per PC  
The counts of the genes determine the color on the heat map

Arguments for the DimHeatmap() function: 

- *dims*: which PCs to plot 
- *cells*: how many cells to plot 
- *balanced*: plot equal number of genes with highest and lowest weights?
- *fast=FALSE*: nicer and customizable plot with ggplot2 but much slower to make
```{r}
DimHeatmap(seuratObj,dims=1:12,cells=500,balanced=TRUE)
```

The more PCs you plot the less clear the plots become: you start seeing noise.
```{r}
DimHeatmap(seuratObj,dims=13:24,cells=500,balanced=TRUE)
DimHeatmap(seuratObj,dims=25:36,cells=500,balanced=TRUE)
```

## 15. Elbow plot of the PCs
Create a PC Elbow plot using ElbowPlot(): a ranking of the PCs based on the percentage of variance explained by each PC to find a cutoff for the p-value.  

Basically, you see where the plot flattens (= elbow)  

Use this plot in combination with the PC heatmap to determine the number of PCs to use for further analysis  

Arguments of this function:

- *object* Seurat object, input are the PC calculations
- *ndims* default show 20 PCs on the plot
- *reduction* default show PCs obtained by PCA
```{r}
ElbowPlot(seuratObj,ndims=50)
```

Based on this plot, we can see that the top 20 PCs retain a lot of information, while other PCs contain progressively less. However, it is still advisable to use more PCs since they might contain information about rare cell types.

Based on all plots combined we would choose the cutoff at PC40. However, the more PCs, the slower the calculations so for the training (to speed up the analysis) we'll settle for 30.  

## 16. Clustering 
We will construct a k-nearest neighbour graph in order to perform a clustering on the graph. This can be generalized as 3 main steps:  

- Build a kNN graph from the data
- Prune spurious connections from kNN graph (optional step). This is a SNN graph.
- Find groups of cells that maximizes the connections within the group compared other groups.

### Building kNN/SNN graph
To construct a kNN graph, we calculate the Euclidean distance between cells in the PCA space. So we will only use the top N PCA dimensions. We will use the same dimensions for computing UMAP/tSNE.

For every cell we are going to find its nearest neighbors (the smallest Euclidean distance), the most similar cells (in terms of gene expression).  

Use FindNeighbors() from Seurat to compute both the kNN and SNN graphs, in which we refine the edge weights between any two cells based on the shared overlap in their local neighborhoods (Jaccard similarity).

Arguments for this function: 

- *dims*: how many PCs to use (cutoff). Recommendation here: as long as you get extra clusters increase the number of PCs 
- *k-param*: by default the 20 nearest neighbors are identified for each cell. Can be varied but impact is limited. 
- *prune.SNN*: by default stringency of overlap removal is 1/15 (0=no pruning ; 1=prune everything). Overlaps between cell neighborhoods are removed in the SNN graph.

```{r}
seuratObj <- FindNeighbors(seuratObj,dims=1:30)
```

Check the names for the graphs in the seurat object.
```{r}
names(seuratObj@graphs)
```

The kNN graph is a matrix where every connection between cells is represented as a 1. This is called an unweighted graph (default in Seurat). Some cell connections can have more importance than others, in that case the scale of the graph goes from 0 to a maximum distance (it's these weights that are calculated based on the overlaps in local neighbourhoods). Usually, the smaller the distance, the closer two points are, the stronger is their connection. This is called a weighted graph. Both weighted and unweighted graphs are suitable for clustering, but clustering on unweighted graphs is faster for large datasets (> 100k cells).  

### Graph-based clustering
Then we are going to find clusters based on the neighbors info. Cells are iteratively grouped cells together. 

In Seurat, FindClusters() will do a graph-based clustering.

```{r}
resToUse <- 0.8
```

Arguments for this function: 

- *object* Seurat object, input are the neighborhood graphs 
- *resolution*: how coarse you want the clustering to be. Higher values create more clusters. Recommendation here: try different values until you get a good tSNE/clustering with biologically meaningful results (between 0.4-1.2 for 3K cells).
- *algorithm* by default the "Louvain" algorithm is used for clustering (1). To use the Leiden algorithm, you need to set *algorithm*=4. We don't observe a big difference between these two algorithms. The Leiden algorithm is typically used in Python pipelines for sc analysis. Algorithm 2 and 3 are variations of the Louvain algorithm. The main difference resides in the granularity of the result (they should produce more, smaller clusters than Louvain).  ?
- *graph.name* which graph to use: kNN or SNN

```{r}
seuratObj <- FindClusters(seuratObj, resolution=resToUse, graph.name="RNA_snn") 
```

The cluster data is stored in the metadata slot
```{r}
head(seuratObj@meta.data) 
```

### Questions
- Repeat clustering with resolution=0.4
- Repeat clustering with resolution=0.8 

If you change dimsToTry and run the clustering again the old cluster data in meta.data is overwritten.  

If you change the resolution and run the clustering again the new cluster data is added to the metadata. The results of the last clustering will be used for downstream analysis.  

After testing several resolutions, you can visualize the results:  
```{r}
#library(clustree)
#clustree(seuratObj@meta.data,prefix="RNA_snn_res.")
```

The stability index from the SC3 package (Kiselev et al. 2017) measures the stability of clusters across resolutions. The stability index is automatically calculated when a clustering tree is built. Note that each level of clustering corresponds to a different resolution.  
```{r}
#clustree(seuratObj@meta.data,prefix="RNA_snn_res.",
#         node_colour="sc3_stability")
```

## 17. Create tSNE plot
A thorough description of tSNE can be found in this [tSNE tutorial](https://distill.pub/2016/misread-tsne/).  

Dimensionality reduction using RunTSNE()  

Arguments of this function:  

- *object* Seurat object, input are typically the PCs
- *reduction* default use PCs obtained by PCA as input
- *dims* default use the first five PCs as input
- *check_duplicates* tSNE will generate an error "duplicates (cells with exactly the same PC coordinates) have to be removed before running tSNE" if there are duplicate cells in the data set. You can avoid this error by setting this parameter to FALSE.  

As input use the same PCs as in the clustering
```{r}
seuratObj <- RunTSNE(seuratObj,dims=1:30,
                     check_duplicates=FALSE)
```

```{r}
DimPlot(seuratObj,reduction="tsne",label=TRUE,label.size=8,pt.size=2) + NoLegend()
```

To color cells from different samples differently
```{r}
DimPlot(seuratObj,reduction="tsne",pt.size=2,group.by="sample")
```

### Questions
- Make a separate tSNE plot for KO and WT (on one graph).  
Hint: use one of the arguments of DimPlot()

## 18. Create UMAP plot
**UMAP or tSNE**
Most people prefer UMAP over tSNE because distances between clusters are more meaningful in UMAPs and UMAP shows the best performance separating cell types ([ref](https://genomebiology.biomedcentral.com/track/pdf/10.1186/s13059-022-02601-5.pdf)).

Dimensionality reduction using RunUMAP()  

Arguments of this function:  

- *object* Seurat object, input are typically the PCs
- *reduction* default use PCs obtained by PCA as input
- *dims* which PCs to use as input
- *n.components* default reduce to 2 dimensions
- *n.neighbors* Larger values will preserve more global structure at the loss of detail. Should be in the range 5 to 50, default is 30. If you want to ensure that the UMAP representation and clustering results are as consistent as possible it's a good idea to set this parameter to the same number of nearest neighbors that was used by FindNeighbors() (k.param: by default 20).
- *n.epochs* parameter of the dimensionality reduction method. Larger values result in higher accuracy. By default value will be selected based on the size of the input dataset (200 for large datasets, 500 for small).
- *min.dist* parameter of the dimensionality reduction method. How tightly can points be compressed together. Larger values ensure points are more evenly distributed, while smaller values allow to optimize more accurately with regard to local structure. Sensible values are in the range 0.001 to 0.5, default is 0.3
- *spread* parameter of the dimensionality reduction method. The effective scale of the points. In combination with *min.dist* this determines how clustered/clumped the points are.

```{r}
seuratObj <- RunUMAP(seuratObj,dims=1:30,n.neighbors=20)
```

Visualize UMAP plot, colored by sample to check for batch effects
```{r}
DimPlot(seuratObj,group.by="sample")
```

Visualize outliers if you haven't removed them  

```{r}
DimPlot(seuratObj,group.by="mito.out.high")
```

In a UMAP plot distances between clusters are more meaningful than in a tSNE plot.
```{r}
DimPlot(object=seuratObj,label=TRUE,label.size=8) + NoLegend() + ggplot2::ggtitle(label="UMAP_on_PCA")
```

If you are comparing multiple settings for *dims* and *resolution* what you will look for is a setting that nicely separates the different clusters. Obviously you can only be sure of the best setting after you have done some annotation of the clusters.  

### Questions 
- Create a UMAP plot for the two samples separately on one graph. Set size of the points to 0.5. 
- Put PCA, tSNE and UMAP next to each other on one graph. Use NoAxes() to remove the axes from the plots and add a title to each plot: "PCA", "tSNE", "UMAP"
- Put UMAP plots of the two clusterings (resolution 0.1 and 0.8) on one graph.  
Hint: look in the metadata to see how these columns are called.

## 19. Interpret the clustering
Idents() specifies the cluster numbers you want to use. Remember that the clustering results for different settings of *resolution* are stored in separate columns in the meta data.  

To print how many cells each cluster contains use table().  

```{r}
Idents(seuratObj) <- seuratObj@meta.data$RNA_snn_res.0.8
table(seuratObj@active.ident)
```

Plot the clustering  

```{r}
p6 <- DimPlot(seuratObj,label=TRUE) + NoLegend() + NoAxes()
p7 <- DimPlot(seuratObj,group.by="sample") + NoAxes()
ggarrange(p6,p7)
```

## 20. Save Seurat object 
Save object so that 

- it can easily be loaded back without having to rerun these computationally intensive steps  
- it's easy to share with collaborators  
```{r}
saveRDS(seuratObj,file="seuratObj.rds")
```
